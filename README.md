# What is Coffee ?

## Introduction     
- Coffee stands for **C**ommon **F**orecast **F**ramework
for **E**veryday **E**ssentials.    
- It is a time-series forecasting tool designed for easy use and high extensibility.     

## Installation
to do    
```python

```

## Background
- Since most time-series forecasts share some similarities, there is no need to re-build wheels with some heavy-duty models.
However, we still need to know the actual business scenarios and some expertise to better solve the problem. There is demand for a collective tool which contains different effective models inside.
- Considering the implementation, we hope this tool can act like a "toolbox" for oridinary users:
    - As long as the input is defined as the required format, Coffee should return the output as reqired format as well.
    - It is easy to add more models into Coffee as long as they follow the same structure.

## How to use
There are only two inputs we need: **Data** and **Params**
### Data      
Data should be in Pandas DataFrame type and contains at least 2 columns.    
- date: date of value (will be transformed to 'yyyy-MM-dd' datetime format)
- value: target value

Below is a sample df for daily total order volume forecast

date | value
--- | ---
2020-01-04 | 29647
2020-01-05 | 50526
2020-01-06 | 11814

### Params
Params is a Python dictionary which contains essential parameters of Coffee model.
```python
params = {'model': 'dual_stage_pairwise',     # model name
          'model_type': 'predict',      # predict: predict the future value based on predict_len; evaluation: predict on historial data for evaluation
          'predict_len': 1,     # predict T+1 or T+N
          'granularity': '1/24',    # daily = 1/24, weekly = 1/168, hourly = 1
          'backtrace_days': 30,     # numbers of date pairs to be generated
          'window_size': 4,     # length of lagged value vector
          'evaluate_type': 'batch_test',  # the way to evaluate the model. batch_test: simple split and test; rolling_test: run rolling_test
          'evaluate_size': 0.2,  # proportion of test data, e.g. use 20% of total data for evaluation
          'external_feature': None,  # external_feature should be in dict, e.g: {'2021-01-01': [1,3,1], '2021-01-02': [2,0,1], ...)}
          'similarity_type': 'dtw',  # cosine, euclidean, dtw ...
          'similarity_feature': None}  # similarity_feature should have the same format as external feature, used for finding similar items
```


## Demo
```python
import coffee
import evaluation

params = {"granularity": "1/24",    # Daily Forecast
          "backtrace_type": "similarity",
          "backtrace_days": 40,     # Find most similar 40 days to generate pairs
          "window_size": 4,         # Use [Vt-4, Vt-3, Vt-2, Vt-1] as feature vector
          "external_feature": external_feature,    # External Feature
          "similarity_type": "dtw",                 # Dynamic Time Warping
          "similarity_feature": similarity_feature, # Similarity Feature
          "ratio": 0.7,             # Take the average of forecast result generated by 70% of most similar dates
          "evaluate_ratio": 0.1     # Use last 10% of dataset for evaluation
         }

# 1.For model evaluation
# This is a one-step function to tell you the performance on historical data.
eval_result = evaluation.evaluation_model(df, params)

# 2.For normal forecast
coffee  = coffee.Coffee(params)
df_preprocessed = coffee.make_dataframe(df)   # Preprocessed dataframe based on time granularity and predict len
processed_data, model = coffee.fit(df_preprocessed)   # Get features and model
forecast = coffee.predict(model, processed_data)   # Predict

# 2.1 One-step function to forecast
coffee  = model.Coffee(params)
forecast = coffee.run_model(df)
```
